{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNdEZxSTIgTH6T/XeE8sw/J",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/carlnaces/test/blob/main/Marketing_AS_LM_Merge.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kMAB72GHRwnM",
        "outputId": "be770448-5d0e-489b-839b-e444b70eb723"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gspread in /usr/local/lib/python3.10/dist-packages (6.0.2)\n",
            "Requirement already satisfied: google-auth in /usr/local/lib/python3.10/dist-packages (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from gspread) (1.2.0)\n",
            "Requirement already satisfied: StrEnum==0.4.15 in /usr/local/lib/python3.10/dist-packages (from gspread) (0.4.15)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib>=0.4.1->gspread) (1.3.1)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (3.2.2)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (2024.2.2)\n"
          ]
        }
      ],
      "source": [
        "# Install the required libraries\n",
        "!pip install gspread google-auth\n",
        "\n",
        "# Import libraries\n",
        "import gspread\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "from google.auth import default\n",
        "\n",
        "# Authenticate and create a client\n",
        "auth.authenticate_user()\n",
        "creds, _ = default()\n",
        "gc = gspread.authorize(creds)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import numpy as np\n",
        "\n",
        "# Open the Google Sheets file (replace 'your_spreadsheet_name' with your file's name)\n",
        "spreadsheet = gc.open(\"Marketing AS to LM\").get_worksheet(0)\n",
        "spreadsheet2 = gc.open(\"Marketing AS to LM\").get_worksheet(1)\n",
        "spreadsheet3 = gc.open(\"Marketing AS to LM\").get_worksheet(2)\n",
        "\n",
        "# Now you can work with the 'worksheet' object, for example, fetching the data\n",
        "data = spreadsheet.get_all_values()\n",
        "data2 = spreadsheet2.get_all_values()\n",
        "data3 = spreadsheet3.get_all_values()\n",
        "\n",
        "#Create Data frames for each sheet and assign it to Keap, Acuity and Actiostep data\n",
        "action = pd.DataFrame(data)\n",
        "lm = pd.DataFrame(data2)\n",
        "keap = pd.DataFrame(data3)\n",
        "\n",
        "#Make each first row as the column headers\n",
        "action.columns = action.iloc[0]\n",
        "lm.columns = lm.iloc[0]\n",
        "keap.columns = keap.iloc[0]\n",
        "\n",
        "action = action.drop(0)\n",
        "lm = lm.drop(0)\n",
        "keap = keap.drop(0)"
      ],
      "metadata": {
        "id": "VOUfBbjDUbmR"
      },
      "execution_count": 203,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#print(action.head(10))\n",
        "#print(lm.head(10))"
      ],
      "metadata": {
        "id": "a7ZHcVRDVI7X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preparing the Actionstep data"
      ],
      "metadata": {
        "id": "bFeAShXBK0ZM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Prep Actionstep Data\n",
        "# Replace carriage return with comma and trim spaces in the 'Client Email' column\n",
        "action['Client Email'] = action['Client Email'].str.replace('\\n', ',').str.strip()\n",
        "\n",
        "# Assuming df is your DataFrame and 'Client Email' is the column containing the email addresses\n",
        "action['Client Email'] = action['Client Email'].str.replace('_\\|\\|_', '')\n",
        "\n",
        "# Assuming df is your DataFrame and 'Client Email' is the column containing the email addresses\n",
        "action['Client Email'] = action['Client Email'].str.strip('_')\n",
        "\n",
        "action['Client Email'] = action['Client Email'].str.replace('__', ',')\n",
        "\n",
        "# Make Emails Lowecase\n",
        "action['Client Email'] = action['Client Email'].str.lower()"
      ],
      "metadata": {
        "id": "t5V0aK4MejDR"
      },
      "execution_count": 204,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert 'Client Email' and 'Matter Type' columns to string data type\n",
        "action[['Client Email', 'Matter Type']] = action[['Client Email', 'Matter Type']].astype(str)\n",
        "\n",
        "# List of columns to convert from string to numeric\n",
        "columns_to_convert = ['Fee Collected (APC)', 'Fee Collected (EP)', 'Fee Collected (EA)', 'Fee Collected (TA)', 'Fee Collected (Old EP)']\n",
        "\n",
        "# Remove dollar signs ($) and commas (,) from the values, convert to numeric, fill NaNs with 0, and ensure two decimal places\n",
        "for column in columns_to_convert:\n",
        "    action[column] = pd.to_numeric(action[column].str.replace('[$,]', '', regex=True), errors='coerce').fillna(0).astype(float)\n",
        "\n",
        "# Round the converted columns to ensure two decimal places\n",
        "action[columns_to_convert] = action[columns_to_convert].round(2)\n",
        "\n",
        "# Create 'Max Fee' column by taking the maximum value across the specified columns and rounding it to two decimal places\n",
        "action['Max Fee'] = action[columns_to_convert].max(axis=1).round(2)\n",
        "\n",
        "# Create a new DataFrame by dropping specified columns\n",
        "action_v2 = action.drop(columns=['Client Last Name', 'Client First Name',\n",
        "                                 'Fee Collected (APC)', 'Fee Collected (EP)',\n",
        "                                 'Fee Collected (EA)', 'Fee Collected (TA)',\n",
        "                                 'Fee Collected (Old EP)'])\n",
        "\n",
        "# Convert 'ID' column to integer\n",
        "action_v2['ID'] = action_v2['ID'].astype(int)\n",
        "\n",
        "# Sort the new DataFrame by 'ID' column in ascending order\n",
        "action_check_sorted = action_v2.sort_values(by='ID', ascending=True)\n",
        "\n",
        "# Replace empty strings in 'Client Email' with NaN and drop rows with NaN in 'Client Email'\n",
        "action_v2['Client Email'] = action_v2['Client Email'].replace('', pd.NA)\n",
        "action_v2 = action_v2.dropna(subset=['Client Email'])"
      ],
      "metadata": {
        "id": "XsTjYCj1feq3"
      },
      "execution_count": 205,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(action_v2.dtypes)\n",
        "action_v2.to_excel('action_v2.xlsx', index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b6Ig10p0fj2u",
        "outputId": "b9958048-5757-4419-90ad-e22b0c017701"
      },
      "execution_count": 206,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "Favorite         object\n",
            "Client Email     object\n",
            "ID                int64\n",
            "Date Created     object\n",
            "Matter Type      object\n",
            "Max Fee         float64\n",
            "dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the 'Client Email split' column into a list of emails\n",
        "action_v2['Client Email List'] = action_v2['Client Email'].str.split(',')\n",
        "\n",
        "# Create a new DataFrame with one row for each email in 'Client Email List'\n",
        "expanded_action_v2 = action_v2.explode('Client Email List')\n",
        "\n",
        "#sort by ID\n",
        "expanded_action_v2 = expanded_action_v2.sort_values(by='ID')\n",
        "\n",
        "columns_to_sort_by = ['ID', 'Max Fee', 'Client Email List']\n",
        "expanded_action_v2 = expanded_action_v2.sort_values(by=columns_to_sort_by, ascending=[True, False, True])\n",
        "\n",
        "columns_to_check = ['ID', 'Date Created', 'Matter Type', 'Client Email', 'Max Fee', 'Client Email List']\n",
        "expanded_action_v2 = expanded_action_v2.drop_duplicates(subset=columns_to_check, keep='first')"
      ],
      "metadata": {
        "id": "is9YdH2ChEIn"
      },
      "execution_count": 207,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "expanded_action_v2.to_excel('expanded_action_v2.xlsx', index=False)"
      ],
      "metadata": {
        "id": "O8t4BTTohv4I"
      },
      "execution_count": 208,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Splitting into Primary and Secondary Emails"
      ],
      "metadata": {
        "id": "ONvZyvTHLF1Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Removing Duplicates\n",
        "# Find the first entry for each ID\n",
        "first_entry_mask = expanded_action_v2.duplicated(subset='ID')\n",
        "\n",
        "# Filter out the first entry for each ID (primary email)\n",
        "primary_email = expanded_action_v2[~first_entry_mask]\n",
        "\n",
        "# Filter the DataFrame to exclude the rows included in primary_email (secondary email)\n",
        "secondary_email = expanded_action_v2[first_entry_mask]"
      ],
      "metadata": {
        "id": "y-JlNY7nJ6Ik"
      },
      "execution_count": 209,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "primary_email.to_excel('primary_email.xlsx', index=False)\n",
        "secondary_email.to_excel('secondary_email.xlsx', index=False)"
      ],
      "metadata": {
        "id": "GIRX8MxuLDAV"
      },
      "execution_count": 210,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prepare Lawmatics Export Data"
      ],
      "metadata": {
        "id": "IhffQDmDLZbS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Clean LM columns first\n",
        "\n",
        "selected_columns = ['id',\n",
        "                    'email',\n",
        "                    'practice_area_name',\n",
        "                    'source_name',\n",
        "                    'Requested Understanding Estate Administration(matter)',\n",
        "                    'Vision Meeting(matter)',\n",
        "                    'Strategy Session(matter)',\n",
        "                    'Actionstep Matter ID(matter)',\n",
        "                    'Discovery Meeting(matter)',\n",
        "                    'Keap Lead Source(matter)',\n",
        "                    'Requested Caregiver Guide(matter)',\n",
        "                    'Requested CSP Guide(matter)',\n",
        "                    'Requested 12 Threats(matter)',\n",
        "                    \"Requested Alzheimer's Guide(matter)\",\n",
        "                    'Requested COVID-19 Economic Relief & Incentives for Small Employers Report(matter)',\n",
        "                    'Requested Hardcopy of CSP Guide(matter)',\n",
        "                    'Requested How to Choose(matter)',\n",
        "                    'Requested Choosing Guardians(matter)',\n",
        "                    'Requested Special Needs Guide(matter)',\n",
        "                    \"Requested Here's the Plan(matter)\",\n",
        "                    'Requested Hardcopy of Caregivers Guide(matter)',\n",
        "                    'Requested Shook 1 Action Plan(matter)',\n",
        "                    \"Reqeusted Parkinson's Peace of Mind(matter)\",\n",
        "                    'Requested Avoid Nursing Home Poverty(matter)',\n",
        "                    'Requested Shook 2 Action Plan(matter)',\n",
        "                    'Requested Hardcopy of 12 Threats(matter)',\n",
        "                    'Requested Supercharge Your IRA(matter)',\n",
        "                    'Requested Understanding VA A&A(matter)',\n",
        "                    'Requested Estate Planning and Coronavirus(matter)',\n",
        "                    'Requested First Steps Checklist(matter)',\n",
        "                    'Requested SECURE Act Memo(matter)',\n",
        "                    \"Requested Business Owner's Guide to Surviving COVID-19(matter)\",\n",
        "                    'Requested CFEP Personal Organizer(matter)',\n",
        "                    'Requested Hardcopy Newsletter(matter)',\n",
        "                    'Requested Hardcopy of Understanding Estate Administration(matter)',\n",
        "                    'created_at']\n",
        "\n",
        "# Method 1: Overwrite the DataFrame with selected columns\n",
        "lm_cleaned = lm[selected_columns]\n",
        "\n",
        "# Clean column names to remove leading/trailing spaces\n",
        "lm_cleaned.columns = lm_cleaned.columns.str.strip()\n",
        "\n",
        "# List of columns to convert to string, using double quotes to handle apostrophes\n",
        "columns_to_convert = ['email',\n",
        "                    'practice_area_name',\n",
        "                    'source_name',\n",
        "                    'Keap Lead Source(matter)']\n",
        "\n",
        "# Check which columns are actually present in the DataFrame\n",
        "existing_columns_to_convert = [col for col in columns_to_convert if col in lm_cleaned.columns]"
      ],
      "metadata": {
        "id": "B-48AygYA2x9"
      },
      "execution_count": 211,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the existing columns to string data type\n",
        "if existing_columns_to_convert:\n",
        "    lm_cleaned[existing_columns_to_convert] = lm_cleaned[existing_columns_to_convert].astype(str)\n",
        "else:\n",
        "    print(\"None of the specified columns exist in the DataFrame.\")\n",
        "\n",
        "# List of columns to convert to int\n",
        "columns_to_convert_to_int = [\n",
        "    'id', 'Actionstep Matter ID(matter)'\n",
        "]\n",
        "\n",
        "# Check if the specified columns exist in the DataFrame and handle them accordingly\n",
        "existing_columns_to_convert = [col for col in columns_to_convert_to_int if col in lm_cleaned.columns]\n",
        "\n",
        "if existing_columns_to_convert:\n",
        "    # Convert columns to numeric, coerce errors to NaN, fill NaNs with a default value (e.g., 0), and convert to int\n",
        "    lm_cleaned[existing_columns_to_convert] = lm_cleaned[existing_columns_to_convert].apply(\n",
        "        pd.to_numeric, errors='coerce').fillna(0).astype(int)\n",
        "else:\n",
        "    print(\"None of the specified columns exist in the DataFrame.\")\n",
        "\n",
        "# List of columns to convert to date\n",
        "columns_to_convert_to_date = [\n",
        "                    'Requested Understanding Estate Administration(matter)',\n",
        "                    'Vision Meeting(matter)',\n",
        "                    'Strategy Session(matter)',\n",
        "                    'Discovery Meeting(matter)',\n",
        "                    'Requested Caregiver Guide(matter)',\n",
        "                    'Requested CSP Guide(matter)',\n",
        "                    'Requested 12 Threats(matter)',\n",
        "                    \"Requested Alzheimer's Guide(matter)\",\n",
        "                    'Requested COVID-19 Economic Relief & Incentives for Small Employers Report(matter)',\n",
        "                    'Requested Hardcopy of CSP Guide(matter)',\n",
        "                    'Requested How to Choose(matter)',\n",
        "                    'Requested Choosing Guardians(matter)',\n",
        "                    'Requested Special Needs Guide(matter)',\n",
        "                    \"Requested Here's the Plan(matter)\",\n",
        "                    'Requested Hardcopy of Caregivers Guide(matter)',\n",
        "                    'Requested Shook 1 Action Plan(matter)',\n",
        "                    \"Reqeusted Parkinson's Peace of Mind(matter)\",\n",
        "                    'Requested Avoid Nursing Home Poverty(matter)',\n",
        "                    'Requested Shook 2 Action Plan(matter)',\n",
        "                    'Requested Hardcopy of 12 Threats(matter)',\n",
        "                    'Requested Supercharge Your IRA(matter)',\n",
        "                    'Requested Understanding VA A&A(matter)',\n",
        "                    'Requested Estate Planning and Coronavirus(matter)',\n",
        "                    'Requested First Steps Checklist(matter)',\n",
        "                    'Requested SECURE Act Memo(matter)',\n",
        "                    \"Requested Business Owner's Guide to Surviving COVID-19(matter)\",\n",
        "                    'Requested CFEP Personal Organizer(matter)',\n",
        "                    'Requested Hardcopy Newsletter(matter)',\n",
        "                    'Requested Hardcopy of Understanding Estate Administration(matter)',\n",
        "                    'created_at']\n",
        "\n",
        "# Check if the specified columns exist in the DataFrame and handle them accordingly\n",
        "existing_columns_to_convert = [col for col in columns_to_convert_to_date if col in lm_cleaned.columns]\n",
        "\n",
        "if existing_columns_to_convert:\n",
        "    # Convert columns to datetime, coerce errors to NaT (Not a Time)\n",
        "    lm_cleaned[existing_columns_to_convert] = lm_cleaned[existing_columns_to_convert].apply(\n",
        "        pd.to_datetime, errors='coerce')\n",
        "else:\n",
        "    print(\"None of the specified columns exist in the DataFrame.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M_kFhyBMBLtO",
        "outputId": "bd8495ff-337f-4f8a-9795-02ffa051fea4"
      },
      "execution_count": 212,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-212-6742869b3043>:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  lm_cleaned[existing_columns_to_convert] = lm_cleaned[existing_columns_to_convert].astype(str)\n",
            "<ipython-input-212-6742869b3043>:17: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  lm_cleaned[existing_columns_to_convert] = lm_cleaned[existing_columns_to_convert].apply(\n",
            "<ipython-input-212-6742869b3043>:60: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  lm_cleaned[existing_columns_to_convert] = lm_cleaned[existing_columns_to_convert].apply(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#print(lm_cleaned.dtypes)\n",
        "lm_cleaned.to_excel('lm_cleaned.xlsx', index=False)"
      ],
      "metadata": {
        "id": "4jzhXdiKI38K"
      },
      "execution_count": 213,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use .loc to avoid SettingWithCopyWarning\n",
        "lm_cleaned.loc[:, 'Had Vision'] = lm_cleaned['Vision Meeting(matter)'].apply(lambda x: 1 if pd.notnull(x) else 0)\n",
        "lm_cleaned.loc[:, 'Had Strategy'] = lm_cleaned['Strategy Session(matter)'].apply(lambda x: 1 if pd.notnull(x) else 0)\n",
        "lm_cleaned.loc[:, 'Had Discovery'] = lm_cleaned['Discovery Meeting(matter)'].apply(lambda x: 1 if pd.notnull(x) else 0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M6gzqlUcJYtG",
        "outputId": "ec962503-30fc-4b21-962e-32b235b9f7f7"
      },
      "execution_count": 214,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-214-0692c624b940>:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  lm_cleaned.loc[:, 'Had Vision'] = lm_cleaned['Vision Meeting(matter)'].apply(lambda x: 1 if pd.notnull(x) else 0)\n",
            "<ipython-input-214-0692c624b940>:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  lm_cleaned.loc[:, 'Had Strategy'] = lm_cleaned['Strategy Session(matter)'].apply(lambda x: 1 if pd.notnull(x) else 0)\n",
            "<ipython-input-214-0692c624b940>:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  lm_cleaned.loc[:, 'Had Discovery'] = lm_cleaned['Discovery Meeting(matter)'].apply(lambda x: 1 if pd.notnull(x) else 0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the date columns to datetime format\n",
        "date_columns = ['Requested Understanding Estate Administration(matter)',\n",
        "                    'Requested Caregiver Guide(matter)',\n",
        "                    'Requested CSP Guide(matter)',\n",
        "                    'Requested 12 Threats(matter)',\n",
        "                    \"Requested Alzheimer's Guide(matter)\",\n",
        "                    'Requested COVID-19 Economic Relief & Incentives for Small Employers Report(matter)',\n",
        "                    'Requested Hardcopy of CSP Guide(matter)',\n",
        "                    'Requested How to Choose(matter)',\n",
        "                    'Requested Choosing Guardians(matter)',\n",
        "                    'Requested Special Needs Guide(matter)',\n",
        "                    \"Requested Here's the Plan(matter)\",\n",
        "                    'Requested Hardcopy of Caregivers Guide(matter)',\n",
        "                    'Requested Shook 1 Action Plan(matter)',\n",
        "                    \"Reqeusted Parkinson's Peace of Mind(matter)\",\n",
        "                    'Requested Avoid Nursing Home Poverty(matter)',\n",
        "                    'Requested Shook 2 Action Plan(matter)',\n",
        "                    'Requested Hardcopy of 12 Threats(matter)',\n",
        "                    'Requested Supercharge Your IRA(matter)',\n",
        "                    'Requested Understanding VA A&A(matter)',\n",
        "                    'Requested Estate Planning and Coronavirus(matter)',\n",
        "                    'Requested First Steps Checklist(matter)',\n",
        "                    'Requested SECURE Act Memo(matter)',\n",
        "                    \"Requested Business Owner's Guide to Surviving COVID-19(matter)\",\n",
        "                    'Requested CFEP Personal Organizer(matter)',\n",
        "                    'Requested Hardcopy Newsletter(matter)',\n",
        "                    'Requested Hardcopy of Understanding Estate Administration(matter)']\n",
        "\n",
        "# Create 'First Lead' column by finding the earliest date\n",
        "lm_cleaned['First Lead'] = lm_cleaned[date_columns].apply(lambda row: row.idxmin() if row.notna().any() else pd.NA, axis=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z-yKVPCxK1ve",
        "outputId": "2f4783f8-e6f6-4334-bf3f-fee12a59128e"
      },
      "execution_count": 215,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-215-57c456838756>:30: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  lm_cleaned['First Lead'] = lm_cleaned[date_columns].apply(lambda row: row.idxmin() if row.notna().any() else pd.NA, axis=1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample data creation for demonstration, replace this with your actual data loading method\n",
        "# lm_cleaned = pd.read_csv('path_to_your_csv_file.csv') or however you load your DataFrame\n",
        "\n",
        "# Create a copy of the DataFrame to avoid SettingWithCopyWarning\n",
        "lm_cleaned_copy = lm_cleaned.copy()\n",
        "\n",
        "# Display initial data for debugging\n",
        "print(\"Initial Data Sample:\")\n",
        "print(lm_cleaned_copy[['email', 'source_name', 'Keap Lead Source(matter)']].head(50))\n",
        "\n",
        "# Check for null values and empty strings in 'source_name'\n",
        "print(\"\\nChecking for null or empty values in 'source_name':\")\n",
        "null_values = lm_cleaned_copy['source_name'].isnull().sum()\n",
        "empty_strings = (lm_cleaned_copy['source_name'].str.strip() == \"\").sum()\n",
        "print(f\"Null values found: {null_values}\")\n",
        "print(f\"Empty strings found: {empty_strings}\")\n",
        "\n",
        "# Function to update 'Keap Lead Source(matter)'\n",
        "def update_keap_lead_source(row):\n",
        "    if pd.notnull(row['source_name']) and row['source_name'].strip() != \"\":\n",
        "        return row['source_name']\n",
        "    else:\n",
        "        return row['Keap Lead Source(matter)']\n",
        "\n",
        "# Apply the function to update 'Keap Lead Source(matter)' column\n",
        "lm_cleaned_copy['Keap Lead Source(matter)'] = lm_cleaned_copy.apply(update_keap_lead_source, axis=1)\n",
        "\n",
        "# Display updated data for verification\n",
        "print(\"\\nUpdated Data Sample:\")\n",
        "print(lm_cleaned_copy[['email', 'source_name', 'Keap Lead Source(matter)']].head(50))\n",
        "\n",
        "# Save the updated DataFrame to an Excel file\n",
        "lm_cleaned_copy.to_excel('updated_lm_cleaned.xlsx', index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "xtncg37NTYaA",
        "outputId": "48192bcd-789e-4cef-dfde-8274e918523f"
      },
      "execution_count": 216,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial Data Sample:\n",
            "0                                         email     source_name  \\\n",
            "1                     aliceboone61921@gmail.com                   \n",
            "2                          eroseville@yahoo.com                   \n",
            "3                                 lcarm@att.net                   \n",
            "4                              jvereen@atmc.net                   \n",
            "5                       akendricks@netscape.net                   \n",
            "6                          pdycornell@gmail.com                   \n",
            "7                         alyssah.o13@gmail.com                   \n",
            "8                          mscandi_99@yahoo.com                   \n",
            "9                        thomashstyer@gmail.com                   \n",
            "10                         tonyrice60@gmail.com                   \n",
            "11                           cwimes02@gmail.com                   \n",
            "12                                                                \n",
            "13                      pauldowsett@hotmail.com                   \n",
            "14                     dalestasiewicz@gmail.com                   \n",
            "15                            fred7barb@aol.com                   \n",
            "16                    opheliaramsey93@gmail.com  Google Organic   \n",
            "17                      celeste3brown@gmail.com                   \n",
            "18                  jimenezestela9999@gmail.com                   \n",
            "19                         atravaglia@gmail.com                   \n",
            "20                         kktalbot57@gmail.com                   \n",
            "21                       rbwilliams55@gmail.com                   \n",
            "22                       price.glenda@yahoo.com                   \n",
            "23                   mabrewerbusiness@gmail.com                   \n",
            "24                    kneisler.nicole@gmail.com                   \n",
            "25                                         none                   \n",
            "26                       nolanowalker@gmail.com                   \n",
            "27                    dericksmith1176@gmail.com                   \n",
            "28                            wwwc309@gmail.com                   \n",
            "29  danfwd+vfwilson_a_nc.rr.com@carolinafep.com                   \n",
            "30                            rayaran@yahoo.com                   \n",
            "31                       wondaabney23@gmail.com      Google LSA   \n",
            "32                            najchow@gmail.com                   \n",
            "33                       rinzaizwerin@gmail.com                   \n",
            "34                          dmjmpetty@gmail.com                   \n",
            "35                   carlton.cj.jones@gmail.com                   \n",
            "36                       liezl_byap@hotmail.com                   \n",
            "37                          4hisfavor@gmail.com                   \n",
            "38                       globalidol27@gmail.com                   \n",
            "39                   imsinfullydivine@yahoo.com                   \n",
            "40                            hkhucks@gmail.com                   \n",
            "41                         fburnette3@gmail.com                   \n",
            "42                      mary.hinton24@gmail.com                   \n",
            "43                                                                \n",
            "44                      crspence12713@gmail.com                   \n",
            "45                 lynn.a.andrew@protonmail.com                   \n",
            "46                     ursula_sellers@yahoo.com                   \n",
            "47                       nancy.doorey@gmail.com                   \n",
            "48                         sarkar1313@gmail.com                   \n",
            "49                     meagan.juracek@gmail.com                   \n",
            "50                             dicu0408@aol.com                   \n",
            "\n",
            "0            Keap Lead Source(matter)  \n",
            "1                             Website  \n",
            "2                      Google Organic  \n",
            "3                             Website  \n",
            "4                             Website  \n",
            "5                                      \n",
            "6                             Website  \n",
            "7                             Website  \n",
            "8                       Facebook Paid  \n",
            "9                             Website  \n",
            "10                      Facebook Paid  \n",
            "11                      Facebook Paid  \n",
            "12                                     \n",
            "13                            Website  \n",
            "14                     Google Organic  \n",
            "15  Referral - From Affiliate/Partner  \n",
            "16                     Google Organic  \n",
            "17                     Google Organic  \n",
            "18                            Website  \n",
            "19           Referral - From Customer  \n",
            "20                            Website  \n",
            "21           Referral - From Customer  \n",
            "22                            Website  \n",
            "23                                     \n",
            "24                     Google Organic  \n",
            "25                     Google Organic  \n",
            "26                     Google Organic  \n",
            "27  Referral - From Affiliate/Partner  \n",
            "28                                     \n",
            "29                            Website  \n",
            "30                     Google Organic  \n",
            "31                                     \n",
            "32                      Facebook Paid  \n",
            "33                     Google Organic  \n",
            "34                            Website  \n",
            "35                            Website  \n",
            "36                            Website  \n",
            "37                            Website  \n",
            "38                            Website  \n",
            "39                            Website  \n",
            "40                            Website  \n",
            "41                            Website  \n",
            "42                     Google Organic  \n",
            "43                                     \n",
            "44                                     \n",
            "45                     Google Organic  \n",
            "46                                     \n",
            "47                     Google Organic  \n",
            "48                      Facebook Paid  \n",
            "49                            Website  \n",
            "50                            Website  \n",
            "\n",
            "Checking for null or empty values in 'source_name':\n",
            "Null values found: 0\n",
            "Empty strings found: 21224\n",
            "\n",
            "Updated Data Sample:\n",
            "0                                         email     source_name  \\\n",
            "1                     aliceboone61921@gmail.com                   \n",
            "2                          eroseville@yahoo.com                   \n",
            "3                                 lcarm@att.net                   \n",
            "4                              jvereen@atmc.net                   \n",
            "5                       akendricks@netscape.net                   \n",
            "6                          pdycornell@gmail.com                   \n",
            "7                         alyssah.o13@gmail.com                   \n",
            "8                          mscandi_99@yahoo.com                   \n",
            "9                        thomashstyer@gmail.com                   \n",
            "10                         tonyrice60@gmail.com                   \n",
            "11                           cwimes02@gmail.com                   \n",
            "12                                                                \n",
            "13                      pauldowsett@hotmail.com                   \n",
            "14                     dalestasiewicz@gmail.com                   \n",
            "15                            fred7barb@aol.com                   \n",
            "16                    opheliaramsey93@gmail.com  Google Organic   \n",
            "17                      celeste3brown@gmail.com                   \n",
            "18                  jimenezestela9999@gmail.com                   \n",
            "19                         atravaglia@gmail.com                   \n",
            "20                         kktalbot57@gmail.com                   \n",
            "21                       rbwilliams55@gmail.com                   \n",
            "22                       price.glenda@yahoo.com                   \n",
            "23                   mabrewerbusiness@gmail.com                   \n",
            "24                    kneisler.nicole@gmail.com                   \n",
            "25                                         none                   \n",
            "26                       nolanowalker@gmail.com                   \n",
            "27                    dericksmith1176@gmail.com                   \n",
            "28                            wwwc309@gmail.com                   \n",
            "29  danfwd+vfwilson_a_nc.rr.com@carolinafep.com                   \n",
            "30                            rayaran@yahoo.com                   \n",
            "31                       wondaabney23@gmail.com      Google LSA   \n",
            "32                            najchow@gmail.com                   \n",
            "33                       rinzaizwerin@gmail.com                   \n",
            "34                          dmjmpetty@gmail.com                   \n",
            "35                   carlton.cj.jones@gmail.com                   \n",
            "36                       liezl_byap@hotmail.com                   \n",
            "37                          4hisfavor@gmail.com                   \n",
            "38                       globalidol27@gmail.com                   \n",
            "39                   imsinfullydivine@yahoo.com                   \n",
            "40                            hkhucks@gmail.com                   \n",
            "41                         fburnette3@gmail.com                   \n",
            "42                      mary.hinton24@gmail.com                   \n",
            "43                                                                \n",
            "44                      crspence12713@gmail.com                   \n",
            "45                 lynn.a.andrew@protonmail.com                   \n",
            "46                     ursula_sellers@yahoo.com                   \n",
            "47                       nancy.doorey@gmail.com                   \n",
            "48                         sarkar1313@gmail.com                   \n",
            "49                     meagan.juracek@gmail.com                   \n",
            "50                             dicu0408@aol.com                   \n",
            "\n",
            "0            Keap Lead Source(matter)  \n",
            "1                             Website  \n",
            "2                      Google Organic  \n",
            "3                             Website  \n",
            "4                             Website  \n",
            "5                                      \n",
            "6                             Website  \n",
            "7                             Website  \n",
            "8                       Facebook Paid  \n",
            "9                             Website  \n",
            "10                      Facebook Paid  \n",
            "11                      Facebook Paid  \n",
            "12                                     \n",
            "13                            Website  \n",
            "14                     Google Organic  \n",
            "15  Referral - From Affiliate/Partner  \n",
            "16                     Google Organic  \n",
            "17                     Google Organic  \n",
            "18                            Website  \n",
            "19           Referral - From Customer  \n",
            "20                            Website  \n",
            "21           Referral - From Customer  \n",
            "22                            Website  \n",
            "23                                     \n",
            "24                     Google Organic  \n",
            "25                     Google Organic  \n",
            "26                     Google Organic  \n",
            "27  Referral - From Affiliate/Partner  \n",
            "28                                     \n",
            "29                            Website  \n",
            "30                     Google Organic  \n",
            "31                         Google LSA  \n",
            "32                      Facebook Paid  \n",
            "33                     Google Organic  \n",
            "34                            Website  \n",
            "35                            Website  \n",
            "36                            Website  \n",
            "37                            Website  \n",
            "38                            Website  \n",
            "39                            Website  \n",
            "40                            Website  \n",
            "41                            Website  \n",
            "42                     Google Organic  \n",
            "43                                     \n",
            "44                                     \n",
            "45                     Google Organic  \n",
            "46                                     \n",
            "47                     Google Organic  \n",
            "48                      Facebook Paid  \n",
            "49                            Website  \n",
            "50                            Website  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vjm316bNnYET"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# List of columns to keep\n",
        "columns_to_keep = ['id',\n",
        "                    'email',\n",
        "                    'practice_area_name',\n",
        "                    'Vision Meeting(matter)',\n",
        "                    'Strategy Session(matter)',\n",
        "                    'Actionstep Matter ID(matter)',\n",
        "                    'Discovery Meeting(matter)',\n",
        "                    'Keap Lead Source(matter)',\n",
        "                    'created_at',\n",
        "                    'Had Vision',\n",
        "                   'Had Strategy',\n",
        "                   'Had Discovery',\n",
        "                   'First Lead']\n",
        "\n",
        "# Drop all other columns\n",
        "lm_cleaned = lm_cleaned_copy[columns_to_keep]"
      ],
      "metadata": {
        "id": "7Kuf-ZqKMawl"
      },
      "execution_count": 217,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sort by 'created_at' and then by 'email'\n",
        "lm_cleaned = lm_cleaned.sort_values(by=['created_at', 'email'])"
      ],
      "metadata": {
        "id": "dpbwSXL3VzQs"
      },
      "execution_count": 218,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get unique values of 'Matter Type' column\n",
        "unique_matter_types = primary_email['Matter Type'].unique()\n",
        "\n",
        "# Create an empty dictionary to store filtered DataFrames\n",
        "filtered_dataframes = {}\n",
        "\n",
        "# Split primary_email into multiple DataFrames based on 'Matter Type'\n",
        "for matter_type in unique_matter_types:\n",
        "    # Remove spaces from matter type for DataFrame name\n",
        "    dataframe_name = matter_type.replace(' ', '_')\n",
        "    filtered_dataframes[dataframe_name] = primary_email[primary_email['Matter Type'] == matter_type]"
      ],
      "metadata": {
        "id": "dZWsX4y2XoUD"
      },
      "execution_count": 219,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# #CHECKING\n",
        "# # Now check the contents of the filtered DataFrames\n",
        "# for dataframe_name, dataframe in filtered_dataframes.items():\n",
        "#     print(f\"\\nDataFrame for Matter Type '{dataframe_name}':\")\n",
        "#     print(dataframe)\n",
        "\n",
        "# # Get the names of the new DataFrames\n",
        "# new_dataframe_names = list(filtered_dataframes.keys())\n",
        "\n",
        "# # Print the names of the new DataFrames\n",
        "# print(\"Names of the new DataFrames:\")\n",
        "# for name in new_dataframe_names:\n",
        "#     print(name)"
      ],
      "metadata": {
        "id": "Tz6GFS2oKc3B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assign the dataframe for 'CFEP Estate Planning' to CFEP_Estate_Planning\n",
        "CFEP_Estate_Planning = filtered_dataframes['CFEP_Estate_Planning']\n",
        "CFEP_Estate_Administration = filtered_dataframes['CFEP_Estate_Administration']\n",
        "CFEP_Guardianship = filtered_dataframes['CFEP_Guardianship']\n",
        "CFEP_Medicaid = filtered_dataframes['CFEP_Medicaid']\n",
        "CFEP_Trust_Administration = filtered_dataframes['CFEP_Trust_Administration']\n",
        "APC_Planning = filtered_dataframes['APC_Planning']"
      ],
      "metadata": {
        "id": "4AoungG-KgKp"
      },
      "execution_count": 220,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save each DataFrame to an Excel file\n",
        "for name, dataframe in filtered_dataframes.items():\n",
        "    filename = f\"{name}.xlsx\"\n",
        "    dataframe.to_excel(filename, index=False)\n",
        "    print(f\"DataFrame saved to '{filename}'.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xQXi3Nvjdeeh",
        "outputId": "3057f774-6557-4fc1-c129-02673075a9e1"
      },
      "execution_count": 221,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame saved to 'CFEP_Estate_Planning.xlsx'.\n",
            "DataFrame saved to 'CFEP_Trust_Administration.xlsx'.\n",
            "DataFrame saved to 'CFEP_Medicaid.xlsx'.\n",
            "DataFrame saved to 'CFEP_Estate_Administration.xlsx'.\n",
            "DataFrame saved to 'CFEP_Guardianship.xlsx'.\n",
            "DataFrame saved to 'APC_Planning.xlsx'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#print(lm_cleaned.dtypes)\n",
        "lm_cleaned.to_excel('lm_cleaned.xlsx', index=False)"
      ],
      "metadata": {
        "id": "iCXH35gZNNJM"
      },
      "execution_count": 222,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step by step merge done here. This step is for CFEP Estate Planning.\n"
      ],
      "metadata": {
        "id": "wqxkECnKmNGR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter lm_cleaned for 'Estate Planning' and 'Estate Planning Update' practice areas\n",
        "lm_cleaned_filtered = lm_cleaned[(lm_cleaned['practice_area_name'] == 'Estate Planning') | (lm_cleaned['practice_area_name'] == 'Estate Planning Update')]\n",
        "\n",
        "# Merge lm_cleaned_filtered with CFEP Estate Planning dataframe using left join\n",
        "merged_df1 = pd.merge(lm_cleaned_filtered, CFEP_Estate_Planning.drop_duplicates('Client Email List'), left_on='email', right_on='Client Email List', how='left', indicator=True)\n",
        "\n",
        "# Merge lm_cleaned with CFEP Estate Planning dataframe using left join\n",
        "merged_df2 = pd.merge(lm_cleaned, CFEP_Estate_Planning.drop_duplicates('Client Email List'), left_on='email', right_on='Client Email List', how='left', indicator=True)\n",
        "\n",
        "# Filter rows that were not merged in merged_df2\n",
        "unmerged_df2 = merged_df2[merged_df2['_merge'] == 'left_only']\n",
        "\n",
        "# Concatenate the merged dataframes\n",
        "# FINAL TABLE HERE FOR CFEP ESTATE PLANNING\n",
        "final_merged_df = pd.concat([merged_df1, unmerged_df2]).drop_duplicates()\n",
        "\n",
        "# Save the merged dataframe to an Excel file\n",
        "final_merged_df.to_excel('final_merged_data.xlsx', index=False)\n",
        "\n",
        "# Filter rows from CFEP_Estate_Planning that were not merged\n",
        "unmatched_CFEP_Estate_Planning = CFEP_Estate_Planning[~CFEP_Estate_Planning['Client Email List'].isin(final_merged_df['Client Email List'])]\n",
        "\n",
        "# Save the unmatched rows to a new dataframe\n",
        "unmatched_CFEP_Estate_Planning.to_excel('unmatched_CFEP_Estate_Planning.xlsx', index=False)\n"
      ],
      "metadata": {
        "id": "mmo5_C7djMPk"
      },
      "execution_count": 223,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter final_merged_df for 'Estate Administration' practice area\n",
        "final_merged_estate_administration = final_merged_df[final_merged_df['practice_area_name'] == 'Estate Administration']\n",
        "\n",
        "# Merge final_merged_estate_administration with CFEP Estate Administration dataframe using left join\n",
        "#merged_df_estate_administration = pd.merge(final_merged_estate_administration, CFEP_Estate_Administration, left_on='email', right_on='Client Email List', how='left')\n",
        "\n",
        "# Merge final_merged_estate_administration with CFEP Estate Administration dataframe using left join\n",
        "merged_df_estate_administration = pd.merge(final_merged_estate_administration, CFEP_Estate_Administration, left_on='email', right_on='Client Email List', how='left', indicator='_merge_indicator')\n",
        "\n",
        "# Save the merged dataframe to an Excel file\n",
        "merged_df_estate_administration.to_excel('merged_estate_administration.xlsx', index=False)\n",
        "\n",
        "# Filter final_merged_df for rows not in 'Estate Administration' practice area\n",
        "unmatched_rows = final_merged_df[final_merged_df['practice_area_name'] != 'Estate Administration']\n",
        "\n",
        "# Save the unmatched rows to an Excel file\n",
        "unmatched_rows.to_excel('unmatched_rows.xlsx', index=False)\n",
        "\n",
        "# Merge merged_df_estate_administration with unmatched_rows\n",
        "merged_df_with_unmatched = pd.concat([merged_df_estate_administration, unmatched_rows])\n",
        "\n",
        "# Save the merged dataframe to an Excel file\n",
        "## FINAL TABLE FOR ESTATE PLANNING AND ESTATE ADMINISTRATION\n",
        "merged_df_with_unmatched.to_excel('FINAL_EP_EA.xlsx', index=False)\n",
        "\n",
        "# Filter rows from CFEP_Estate_Administration that were not merged\n",
        "unmatched_CFEP_Estate_Administration = CFEP_Estate_Administration[~CFEP_Estate_Administration['Client Email List'].isin(merged_df_with_unmatched['Client Email List_y'])]\n",
        "\n",
        "# Save the unmatched rows to a new dataframe\n",
        "unmatched_CFEP_Estate_Administration.to_excel('unmatched_CFEP_Estate_Administration.xlsx', index=False)\n",
        "\n"
      ],
      "metadata": {
        "id": "Rh_kwOmxP6tS"
      },
      "execution_count": 224,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#TAKE NOTE OF UNMERGED DATA\n",
        "\n",
        "unmatched_CFEP = pd.concat([unmatched_CFEP_Estate_Planning,\n",
        "                            unmatched_CFEP_Estate_Administration,\n",
        "                            CFEP_Medicaid,\n",
        "                            CFEP_Trust_Administration,\n",
        "                            CFEP_Guardianship,\n",
        "                            APC_Planning])\n",
        "\n",
        "unmatched_CFEP.to_excel('unmatched_CFEP.xlsx', index=False)"
      ],
      "metadata": {
        "id": "G2kmq4FIzWG0"
      },
      "execution_count": 225,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#CLEAN FINAL EP AND EA Dataframe.\n",
        "# TAKE NOTE AS WELL of the remaining rows from secondary_email.\n",
        "\n",
        "# Move values from 'Vision Meeting(matter)' to 'Discovery Meeting(matter)'\n",
        "condition = (merged_df_with_unmatched['practice_area_name'] == 'Estate Administration') & (merged_df_with_unmatched['Vision Meeting(matter)'].notnull())\n",
        "\n",
        "# Update 'Discovery Meeting(matter)' column with the values from 'Vision Meeting(matter)'\n",
        "merged_df_with_unmatched.loc[condition, 'Discovery Meeting(matter)'] = merged_df_with_unmatched.loc[condition, 'Vision Meeting(matter)']\n",
        "\n",
        "# Set 'Vision Meeting(matter)' column to NaN or empty after moving the values\n",
        "merged_df_with_unmatched.loc[condition, 'Vision Meeting(matter)'] = None  # or use np.nan for NaN values\n",
        "\n",
        "\n",
        "# Use .loc to avoid SettingWithCopyWarning\n",
        "merged_df_with_unmatched.loc[:, 'Had Vision'] = merged_df_with_unmatched['Vision Meeting(matter)'].apply(lambda x: 1 if pd.notnull(x) else 0)\n",
        "merged_df_with_unmatched.loc[:, 'Had Strategy'] = merged_df_with_unmatched['Strategy Session(matter)'].apply(lambda x: 1 if pd.notnull(x) else 0)\n",
        "merged_df_with_unmatched.loc[:, 'Had Discovery'] = merged_df_with_unmatched['Discovery Meeting(matter)'].apply(lambda x: 1 if pd.notnull(x) else 0)\n",
        "\n",
        "# Check the final state of the dataframe to confirm the changes\n",
        "#print(merged_df_with_unmatched.head())\n",
        "\n",
        "# Save the modified dataframe to an Excel file\n",
        "merged_df_with_unmatched.to_excel('FINAL_FINAL_EP_EA.xlsx', index=False)\n"
      ],
      "metadata": {
        "id": "kwwgYT3Vx4Ob"
      },
      "execution_count": 226,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# List of columns to keep\n",
        "columns_to_keep = [ 'email',\n",
        "                    'practice_area_name',\n",
        "                    'Vision Meeting(matter)',\n",
        "                    'Strategy Session(matter)',\n",
        "                    'Actionstep Matter ID(matter)',\n",
        "                    'Discovery Meeting(matter)',\n",
        "                    'Keap Lead Source(matter)',\n",
        "                    'created_at',\n",
        "                    'Had Vision',\n",
        "                   'Had Strategy',\n",
        "                   'Had Discovery',\n",
        "                   'First Lead',\n",
        "                    'ID_y',\n",
        "                    'Date Created_y',\n",
        "                    'Max Fee_y',\n",
        "                    'ID',\n",
        "                    'Date Created',\n",
        "                    'Max Fee']\n",
        "\n",
        "# Drop all other columns\n",
        "merged_df_with_unmatched = merged_df_with_unmatched[columns_to_keep]\n",
        "\n",
        "# Save the modified dataframe to an Excel file\n",
        "merged_df_with_unmatched.to_excel('FINAL_FINAL_EP_EA.xlsx', index=False)"
      ],
      "metadata": {
        "id": "Ba_-2d3VKLJ5"
      },
      "execution_count": 227,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Clean email addresses\n",
        "# Define the unwanted email values\n",
        "unwanted_emails = [\"\", None, \"none@example.com\", \"none@none.com\", 'none']\n",
        "\n",
        "# Remove rows where 'email' is in the unwanted emails list\n",
        "cleaned_df = merged_df_with_unmatched[~merged_df_with_unmatched['email'].isin(unwanted_emails)]\n",
        "\n",
        "# Optionally, you can also remove rows with completely blank email values that might not be caught by the above\n",
        "cleaned_df = cleaned_df[cleaned_df['email'].str.strip() != \"\"]\n",
        "\n",
        "\n",
        "# Save the cleaned DataFrame to an Excel file\n",
        "cleaned_df.to_excel('cleaned_merged_df_with_unmatched.xlsx', index=False)\n"
      ],
      "metadata": {
        "id": "rwwuA3SybtFZ"
      },
      "execution_count": 228,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine 'ID_y' and 'ID' into a single 'ID' column\n",
        "cleaned_df['ID'] = cleaned_df['ID_y'].combine_first(cleaned_df['ID'])\n",
        "\n",
        "# Combine 'Max Fee_y' and 'Max Fee' into a single 'Max Fee' column\n",
        "cleaned_df['Max Fee'] = cleaned_df['Max Fee_y'].combine_first(cleaned_df['Max Fee'])\n",
        "\n",
        "# Combine 'Max Fee_y' and 'Max Fee' into a single 'Max Fee' column\n",
        "cleaned_df['Date Created'] = cleaned_df['Date Created_y'].combine_first(cleaned_df['Date Created'])\n",
        "\n",
        "# Drop the old columns\n",
        "cleaned_df.drop(columns=['ID_y', 'Max Fee_y','Date Created_y'], inplace=True)\n",
        "\n",
        "# Save the cleaned DataFrame to an Excel file\n",
        "cleaned_df.to_excel('cleaned_merged_df_with_unmatched.xlsx', index=False)"
      ],
      "metadata": {
        "id": "Ia57cqGMeAcC"
      },
      "execution_count": 229,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# List of columns to keep\n",
        "columns_to_keep = ['Email',\n",
        "                   'Leadsource']\n",
        "\n",
        "# Drop all other columns\n",
        "keap = keap[columns_to_keep]\n",
        "\n",
        "# Save the modified dataframe to an Excel file\n",
        "keap.to_excel('keap.xlsx', index=False)"
      ],
      "metadata": {
        "id": "9WQHcCXHf4t2"
      },
      "execution_count": 230,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Merge final_merged_estate_administration with CFEP Estate Administration dataframe using left join\n",
        "merged_df_FINAL = pd.merge(cleaned_df, keap, left_on='email', right_on='Email', how='left')\n",
        "\n",
        "#merged_df_FINAL['Leadsource'] = merged_df_FINAL.apply(lambda x: x['Leadsource'] if pd.notnull(x['Keap Lead Source(matter)']) else x['Keap Lead Source(matter)'], axis=1)\n",
        "\n",
        "merged_df_FINAL['Leadsource'].fillna(merged_df_FINAL['Keap Lead Source(matter)'], inplace=True)\n",
        "\n",
        "# Save the cleaned DataFrame to an Excel file\n",
        "merged_df_FINAL.to_excel('merged_df_FINAL.xlsx', index=False)"
      ],
      "metadata": {
        "id": "UVfYkqkkhput"
      },
      "execution_count": 231,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Create a copy of the DataFrame to avoid SettingWithCopyWarning\n",
        "merged_df_FINAL_copy = merged_df_FINAL.copy()\n",
        "\n",
        "# Function to update 'Keap Lead Source(matter)'\n",
        "def update_keap_lead_source(row):\n",
        "    if pd.notnull(row['Keap Lead Source(matter)']) and row['Keap Lead Source(matter)'].strip() != \"\":\n",
        "        return row['Keap Lead Source(matter)']\n",
        "    else:\n",
        "        return row['Leadsource']\n",
        "\n",
        "# Apply the function to update 'Keap Lead Source(matter)' column\n",
        "merged_df_FINAL_copy['Leadsource'] = merged_df_FINAL_copy.apply(update_keap_lead_source, axis=1)\n",
        "\n",
        "\n",
        "# Save the updated DataFrame to an Excel file\n",
        "merged_df_FINAL_copy.to_excel('merged_df_FINAL_copy.xlsx', index=False)"
      ],
      "metadata": {
        "id": "TlciiE6TnZ69"
      },
      "execution_count": 232,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# List of columns to keep\n",
        "columns_to_keep = [ 'email',\n",
        "                    'practice_area_name',\n",
        "                    'Vision Meeting(matter)',\n",
        "                    'Strategy Session(matter)',\n",
        "                    'Actionstep Matter ID(matter)',\n",
        "                    'Discovery Meeting(matter)',\n",
        "                    'created_at',\n",
        "                    'Had Vision',\n",
        "                   'Had Strategy',\n",
        "                   'Had Discovery',\n",
        "                   'First Lead',\n",
        "                    'ID',\n",
        "                    'Date Created',\n",
        "                    'Max Fee',\n",
        "                    'Leadsource']\n",
        "\n",
        "# Drop all other columns\n",
        "FINAL_TABLE = merged_df_FINAL_copy[columns_to_keep]\n",
        "\n",
        "# Save the modified dataframe to an Excel file\n",
        "FINAL_TABLE.to_excel('FINAL_TABLE.xlsx', index=False)"
      ],
      "metadata": {
        "id": "VOMcmUgLo90a"
      },
      "execution_count": 234,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "9Uh905i1eKgt"
      }
    }
  ]
}